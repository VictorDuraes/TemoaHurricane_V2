{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "if (typeof IPython !== 'undefined') { IPython.OutputArea.prototype._should_scroll = function(lines){ return false; }}",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.00] Initializing mpi-sppy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, \"../temoa_stochastic/data_processing/\")\n",
    "sys.path.insert(0, \"../temoa_stochastic/temoa_model\") #temoa model module\n",
    "import temoa_model\n",
    "import temoa_config  \n",
    "\n",
    "#mpi-sppy\n",
    "import mpisppy.phbase\n",
    "import mpisppy.opt.ph\n",
    "import mpisppy.opt.aph\n",
    "import mpisppy.scenario_tree as scenario_tree\n",
    "import pyomo.environ as pyo\n",
    "import mpisppy.utils.sputils as sputils\n",
    "import sqlite3\n",
    "\n",
    "#Delete contents of the folder with the input data for TEMOA created in the previous run\n",
    "def create_or_delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Contents of folder '{folder_path}' deleted successfully.\")\n",
    "    else:\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "        \n",
    "#Block Some Prints from TEMOA, too much noise\n",
    "temp_stdout = None\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    global temp_stdout\n",
    "    temp_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    global temp_stdout\n",
    "    sys.stdout = temp_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of folder './Import2TemoaFiles/' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "PowerSystemFileName=\"NC_EnergySystem2023.sqlite\"\n",
    "PathPowerSystemData=\"./InputData/\"+PowerSystemFileName\n",
    "PercentageDamagePath=\"./InputData/PercentageHurricaneDamage.xlsx\"\n",
    "ProbabilityScenariosPath=\"./InputData/ProbabilityEachScenario.xlsx\"\n",
    "\n",
    "PathWriteTemoaInputData=\"./Import2TemoaFiles/\"\n",
    "PathScenarioTree=PathWriteTemoaInputData+\"Scenarios/\"\n",
    "\n",
    "\n",
    "#Delete contents of the folder with the input data for TEMOA created in the previous run\n",
    "create_or_delete_folder(PathWriteTemoaInputData)\n",
    "shutil.copyfile(PathPowerSystemData, PathWriteTemoaInputData+PowerSystemFileName)#copy of .sqlite file\n",
    "\n",
    "df_percentage_damage = pd.read_excel(PercentageDamagePath)\n",
    "df_probability_scenarios = pd.read_excel(ProbabilityScenariosPath)\n",
    "os.makedirs(PathScenarioTree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Scenario Tree Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a .dat file from the.sqlite file\n",
    "DatFilePath=PathScenarioTree+\"R_.dat\"#Root node\n",
    "\n",
    "class C_Options:\n",
    "  def __init__(self, myopic=False, mga_weight=False):\n",
    "    self.myopic = myopic\n",
    "    self.mga_weight = mga_weight\n",
    "\n",
    "options=C_Options()\n",
    "blockPrint()\n",
    "temoa_config.db_2_dat(PathPowerSystemData,DatFilePath,options)\n",
    "enablePrint()\n",
    "\n",
    "#Create a pyomo isntance of TEMOA\n",
    "TEMOA_Model=temoa_model.temoa_create_model()\n",
    "blockPrint()\n",
    "Instance = TEMOA_Model.create_instance( DatFilePath ) \n",
    "enablePrint()\n",
    "\n",
    "TimeStages = sorted( getattr(Instance, 'time_optimize').data() )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMOA_CAPREDUCTION_Keys= list(Instance.CapReduction.keys())\n",
    "# dir_CAPREDUCTION_Keys={ \"Regions\": np.array([i[0] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Periods\": np.array([i[1] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Tech\":    np.array([i[2] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Vintage\": np.array([i[3] for i in TEMOA_CAPREDUCTION_Keys]),\n",
    "#                         \"Key\":     TEMOA_CAPREDUCTION_Keys}\n",
    "\n",
    "#Since I represented all costs even if they are zero, I can use CostFixed to get valid indexed for capacity reduction\n",
    "con = sqlite3.connect(PathPowerSystemData)\n",
    "ValidIdxForCapReduction_sql = pd.read_sql_query(\"SELECT * FROM CostFixed\", con)\n",
    "con.close()\n",
    "\n",
    "dir_CAPREDUCTION_Keys={ \"Regions\": ValidIdxForCapReduction_sql[\"regions\"].values,\n",
    "                        \"Periods\": ValidIdxForCapReduction_sql[\"periods\"].values,\n",
    "                        \"Tech\":    ValidIdxForCapReduction_sql[\"tech\"].values,\n",
    "                        \"Vintage\": ValidIdxForCapReduction_sql[\"vintage\"].values}\n",
    "\n",
    "\n",
    "def WriteNodeData(NodeName, CapReductionNodeInfo, PathScenarioTree=PathScenarioTree, dir_CAPREDUCTION_Keys=dir_CAPREDUCTION_Keys):\n",
    "\n",
    "    NodeYear=CapReductionNodeInfo.columns[2]\n",
    "    PreviousNodeYear=CapReductionNodeInfo.columns[3]\n",
    "\n",
    "    LastYear=CapReductionNodeInfo.columns[-1]\n",
    "\n",
    "    TEMOA_Region=dir_CAPREDUCTION_Keys[\"Regions\"]\n",
    "    TEMOA_Period=dir_CAPREDUCTION_Keys[\"Periods\"]\n",
    "    TEMOA_Tech=dir_CAPREDUCTION_Keys[\"Tech\"]\n",
    "    TEMOA_Vintage=dir_CAPREDUCTION_Keys[\"Vintage\"]\n",
    "\n",
    "    file = open(PathScenarioTree+NodeName+\".dat\", \"w\")\n",
    "    Line1=\"param CapReduction:=\\n\"\n",
    "    file.write(Line1)\n",
    "\n",
    "    for row in CapReductionNodeInfo.iterrows():\n",
    "        region=row[1][\"regions\"]\n",
    "        tech=row[1][\"tech\"]\n",
    "\n",
    "        IdxIn2Change=(TEMOA_Region==region)*(TEMOA_Tech==tech)*(TEMOA_Vintage<=PreviousNodeYear)#All other elements must be equal to one which is the default value\n",
    "\n",
    "        TEMOA_Region_tmp=TEMOA_Region[IdxIn2Change]\n",
    "        TEMOA_Period_tmp=TEMOA_Period[IdxIn2Change]\n",
    "        TEMOA_Tech_tmp=TEMOA_Tech[IdxIn2Change]\n",
    "        TEMOA_Vintage_tmp=TEMOA_Vintage[IdxIn2Change]\n",
    "        rate=np.ones(len(TEMOA_Region_tmp))\n",
    "\n",
    "        for v in np.unique(TEMOA_Vintage_tmp):\n",
    "\n",
    "            if v<=LastYear:\n",
    "                IdxIn=(TEMOA_Vintage_tmp<=LastYear)\n",
    "                rate[IdxIn]=row[1][LastYear]\n",
    "            else:\n",
    "                IdxIn=(TEMOA_Vintage_tmp==v)\n",
    "                rate[IdxIn]=row[1][v]\n",
    "            \n",
    "        Lines=[]\n",
    "        for i in range(len(TEMOA_Region_tmp)):\n",
    "            Line=TEMOA_Region_tmp[i] +\"   \"+ str(NodeYear)+\"   \"+TEMOA_Tech_tmp[i]+\"   \"+str(TEMOA_Vintage_tmp[i])+\"   \"+str(rate[i])+\"\\n\"\n",
    "            file.write(Line)\n",
    "\n",
    "    file.write(\";\")\n",
    "    file.close()\n",
    "    #print(f\"File {NodeName}.dat created successfully.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NodeStages=TimeStages\n",
    "NumStages=len(NodeStages)\n",
    "ScenariosEachStage=list(df_probability_scenarios.columns[1:])\n",
    "RootNodeName=\"R_\"\n",
    "\n",
    "LastStageNodesMapped=[RootNodeName]\n",
    "LastStageNodesMapped_tmp=[]\n",
    "CountTimeStages=1\n",
    "\n",
    "while CountTimeStages<NumStages:\n",
    "    print(\"Stage: %d ----ok\"%(CountTimeStages))\n",
    "    for LSNode in LastStageNodesMapped:\n",
    "        for scenario in ScenariosEachStage:\n",
    "            \n",
    "            NodeName=LSNode+scenario+\"_\"\n",
    "            LastStageNodesMapped_tmp.append(NodeName)\n",
    "            ScenariosNeeded=NodeName.split(\"_\")[1:-1]#Sequence of Nodes\n",
    "            ScenariosNeeded.reverse()\n",
    "\n",
    "            #Put together the information of the nodes needed to create the scenario\n",
    "            Vintages=NodeStages[0:CountTimeStages]#Vintage Intervals we need to be aware of\n",
    "            Vintages.reverse()\n",
    "            CapReductionNodeInfo=df_percentage_damage[[\"regions\",\"tech\"]].copy()\n",
    "\n",
    "            CurrentTimeStage=NodeStages[CountTimeStages]\n",
    "            CapReductionNodeInfo[CurrentTimeStage]=1 \n",
    "            for i in range(len(Vintages)):\n",
    "                Vintage=Vintages[i]# Capacity reduction for any vintage at this one or before for the last vintage (i.e. 2023)\n",
    "                s_tmp=ScenariosNeeded[0:i+1] #Scenarios associated with the vintage\n",
    "                \n",
    "                CapReductionNodeInfo[Vintage]=1 #Capacity reduction for technologies deployed before this specific vintage\n",
    "\n",
    "                for s in s_tmp:\n",
    "                    P_DamageNodeInfo=df_percentage_damage[s]\n",
    "                    CapReductionNodeInfo[Vintage]=CapReductionNodeInfo[Vintage]*(1-P_DamageNodeInfo)\n",
    "\n",
    "            WriteNodeData(NodeName, CapReductionNodeInfo)\n",
    "\n",
    "    CountTimeStages=CountTimeStages+1        \n",
    "    LastStageNodesMapped=LastStageNodesMapped_tmp\n",
    "    LastStageNodesMapped_tmp=[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param ( object ):\n",
    "\t# will be common to all Parameters, so no sense in storing it N times\n",
    "\tstochasticset = None\n",
    "\n",
    "\t  # this saves a noticeable amount of memory, and mild decrease in time\n",
    "\t__slots__ = ('items', 'name', 'spoint', 'param', 'my_keys', 'model_keys',\n",
    "\t             'skeys')\n",
    "\n",
    "\tdef __init__ ( self, **kwargs ):\n",
    "\n",
    "\t\t# At the point someone is using this class, they probably know what\n",
    "\t\t# they're doing, so intentionally die at this point if any of these\n",
    "\t\t# items are not passed.  They're all mandatory.\n",
    "\t\tname   = kwargs.pop('param')   # parameter in question to modify\n",
    "\t\tspoint = kwargs.pop('spoint')  # stochastic point at which to do it\n",
    "\t\trates  = kwargs.pop('rates')   # how much to vary the parameter\n",
    "\t\tpidx   = int( kwargs.pop('stochastic_index') )\n",
    "\n",
    "\t\t#print(instance)\n",
    "\t\tparam = getattr( instance, name )\n",
    "\n",
    "        \n",
    "\t\tindices = tuple()\n",
    "\t\tpindex = param.index_set()\n",
    "\t\t#if isinstance( pindex, _SetProduct ):\n",
    "\t\tif pindex.dimen>1:\n",
    "            #_SetProduct\n",
    "\t\t\tgetname = lambda x: x.name\n",
    "\t\t\tindices = [ getname(i) for i in pindex.set_tuple ]\n",
    "\t\t\tskeys   = lambda: (' '.join(str(i) for i in k) for k in self.model_keys)\n",
    "\n",
    "\t\t\tkeys = param.keys()\n",
    "\t\t\tf = lambda x: x[pidx] == spoint\n",
    "\t\t\tr = lambda x: tuple(x[0:pidx] + x[pidx+1:])\n",
    "\t\t\t    # reduce keys to remove stochastic parameter\n",
    "\n",
    "\t\telif pindex.dimen==1:\n",
    "            #SimpleSet\n",
    "\t\t\t# this is under sparse keys\n",
    "\t\t\tindices = (param.name,)\n",
    "\t\t\tskeys = lambda: (' '.join(str(i) for i in self.model_keys) )\n",
    "\n",
    "\t\t\tkeys = param.keys()\n",
    "\t\t\tf = lambda x: x[pidx] == spoint\n",
    "\t\t\tr = lambda x: tuple(x[0:pidx] + x[pidx +1:])\n",
    "\n",
    "\t\t# we filter out the spoint because it's inherently known by TreeNode,\n",
    "\t\t# which \"owns\" /this/ Param\n",
    "\t\tmodel_keys = list(filter( f, keys ))\n",
    "\t\tmy_keys    = list(map( r, model_keys ))\n",
    "\n",
    "\t\titems = dict()\n",
    "\n",
    "\t\tfor actual, mine in zip(model_keys, my_keys):\n",
    "\t\t\trate = 1\n",
    "\n",
    "\t\t\tfor pattern, r in rates:\n",
    "\t\t\t\tkeys = pattern.split(',')\n",
    "\t\t\t\tmatch = True\n",
    "\t\t\t\tfor p, t in zip(keys, mine):  # \"pattern\", \"test\"\n",
    "\t\t\t\t\tif '*' == p: continue\n",
    "\t\t\t\t\tif t != p:\n",
    "\t\t\t\t\t\tmatch = False\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tif match:\n",
    "\t\t\t\t\trate = r\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\titems[ mine ] = Storage()\n",
    "\t\t\ttry:\n",
    "\t\t\t\titems[ mine ].value = param[ actual ]   # pulled from model\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\titems[ mine ].value = 0\n",
    "\t\t\titems[ mine ].rate  = rate\n",
    "\n",
    "\t\tself.items      = items\n",
    "\t\tself.name       = name\n",
    "\t\tself.spoint     = spoint\n",
    "\t\tself.param      = param\n",
    "\t\tself.my_keys    = my_keys      # these keys are linked -- in the same\n",
    "\t\tself.model_keys = model_keys   #   order -- for zip()-ability\n",
    "\t\tself.skeys      = skeys        # for later, string keys\n",
    "\n",
    "\n",
    "\tdef __iter__ ( self ):\n",
    "\t\treturn self.items.__iter__()\n",
    "\n",
    "\n",
    "\tdef __getitem__ ( self, i ):\n",
    "\t\ttry:\n",
    "\t\t\treturn self.items[ i ]\n",
    "\t\texcept:\n",
    "\t\t\t# it's likely the element did not exist, which hopefully means 0?\n",
    "\t\t\tclass _tmp:\n",
    "\t\t\t\trate = 0\n",
    "\t\t\t\tvalue = 0\n",
    "\t\t\treturn _tmp()\n",
    "\n",
    "\n",
    "\tdef __str__ ( self ):\n",
    "\t\tx = '; '.join(\"(%s, %s)\" % (self[i].value, self[i].rate) for i in self )\n",
    "\t\treturn 'Param(%s): %s' % (self.name, x)\n",
    "\n",
    "\t__repr__ = __str__\n",
    "\n",
    "\n",
    "\tdef as_ampl ( self, comment='' ):\n",
    "\t\tpindex = self.param.index_set()\n",
    "\t\tif comment:\n",
    "\t\t\tcomment = '# Decision: %s\\n\\n' % str(comment)\n",
    "\n",
    "\t\tkeys = self.skeys()\n",
    "\t\tif isinstance( keys, str ):\n",
    "\t\t\tkeys = [ keys ]\n",
    "\n",
    "\t\t# Together, these functions return the length of a printed version of a\n",
    "\t\t# number, in characters.  They are used to make columns of data line up so\n",
    "\t\t# one may have an easier time getting an overall sense of a data file.\n",
    "\t\tdef get_int_padding ( v ):\n",
    "\t\t\treturn len(str(int(v)))\n",
    "        \n",
    "\t\tdef get_str_padding ( index ):\n",
    "\t\t\tdef anonymous_function ( obj ):\n",
    "\t\t\t\tval = obj[ index ]\n",
    "\t\t\t\treturn len(str(val))\n",
    "\t\t\treturn anonymous_function\n",
    "\n",
    "\t\tkeys = tuple( tuple(i.split()) for i in keys )\n",
    "\t\tvals = tuple( self[i].value for i in self.my_keys )\n",
    "        \n",
    "\t\tint_padding = max(map( get_int_padding, vals ))\n",
    "\t\tstr_padding = [\n",
    "\t\t  max(map( get_str_padding(i), keys ))\n",
    "\t\t  for i in range(len(keys[0]))\n",
    "\t\t]\n",
    "\t\tstr_format = '  %-{}s' * len( self.model_keys[0] )\n",
    "\t\tstr_format = str_format.format(*str_padding)\n",
    "\n",
    "\t\tformat = '\\n%%s   %%%ds%%s' % int_padding\n",
    "\t\t# works out to something like '\\n  %s   %8d%-6s'\n",
    "\t\t#                                 index { val }\n",
    "\n",
    "\t\tdata = StringIO()\n",
    "\t\tdata.write( comment + 'param  %s  :=' % self.name )\n",
    "\t\tfor actual_key, this_key in sorted( zip( self.model_keys, self.my_keys )):\n",
    "\t\t\tv = self[this_key].value\n",
    "\t\t\tint_part = str(int(abs(v)))\n",
    "\t\t\tif int_part != str(abs(v)):\n",
    "\t\t\t\tdec_part = str(abs(v))[len(int_part):]\n",
    "\t\t\telse:\n",
    "\t\t\t\tdec_part = ''\n",
    "\n",
    "\t\t\tif v < 0: int_part = '-%d' % int_part\n",
    "\t\t\tindex = str_format % tuple(actual_key)\n",
    "\t\t\tdata.write( format % (index, int_part, dec_part) )\n",
    "\t\tdata.write( '\\n\\t;\\n' )\n",
    "\n",
    "\t\t#return comment + data\n",
    "\t\treturn data.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeNodesforScen(TEMOA_Model, BFs, scennum):\n",
    "    \"\"\" Make just those scenario tree nodes needed by a scenario.\n",
    "        Return them as a list.\n",
    "        NOTE: the nodes depend on the scenario model and are, in some sense,\n",
    "              local to it.\n",
    "        Args:\n",
    "            BFs (list of int): branching factors\n",
    "    \"\"\"\n",
    "    ndn = \"ROOT_\"+str((scennum-1) // BFs[0]) # scennum is one-based\n",
    "    retval = [scenario_tree.ScenarioNode(\"ROOT\",\n",
    "                                         1.0,\n",
    "                                         1,\n",
    "                                         model.StageCost[1],\n",
    "                                         [model.Pgt[1],\n",
    "                                          model.Pgh[1],\n",
    "                                          model.PDns[1],\n",
    "                                          model.Vol[1]],\n",
    "                                         model),\n",
    "              scenario_tree.ScenarioNode(ndn,\n",
    "                                         1.0/BFs[0],\n",
    "                                         2,\n",
    "                                         model.StageCost[2],\n",
    "                                         [model.Pgt[2],\n",
    "                                          model.Pgh[2],\n",
    "                                          model.PDns[2],\n",
    "                                          model.Vol[2]],\n",
    "                                         model, parent_name=\"ROOT\")\n",
    "              ]\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=Instance.CapReduction.extract_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('R2', 2023, 'BLQ_ST_Existing', 1913)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(A.keys())[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=A.copy()\n",
    "B[('R2', 2022, 'BLQ_ST_Existing', 1912)]=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[('R2', 2022, 'BLQ_ST_Existing', 1912)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tree ( stochasticset, spoints, **kwargs ):\n",
    "\tname   = kwargs.get('name')\n",
    "\tbname  = kwargs.get('bname')\n",
    "\tprob   = kwargs.get('prob')\n",
    "\tcprob  = kwargs.get('cprob')\n",
    "\tdecision_list = kwargs.get('decisions')\n",
    "\n",
    "\ttry:\n",
    "\t\tspoint = stochasticset.pop() # stochastic point, use of pop implies ordering\n",
    "\texcept:\n",
    "\t\tSE.write('\\nError: mismatch in specified stochastic set.  Does '\n",
    "\t\t  'stochastic_points match the dat file?')\n",
    "\t\traise\n",
    "\n",
    "\ttreekwargs = dict(\n",
    "\t  spoint   = spoint,\n",
    "\t  name     = name,\n",
    "\t  types    = kwargs.get('types'),\n",
    "\t  rates    = kwargs.get('rates'),\n",
    "\t  filebase = bname,\n",
    "\t  prob     = prob,\n",
    "\t  stochastic_indices = kwargs.get('stochastic_indices'),\n",
    "\t)\n",
    "\n",
    "\tnode = TreeNode( **treekwargs )\n",
    "\tglobal node_count\n",
    "\tnode_count += 1\n",
    "\tinform( '\\b' * (len(str(node_count -1))+1) + str(node_count) + ' ' )\n",
    "\n",
    "\tif spoint not in spoints:\n",
    "\t\tkwargs.update(\n",
    "\t\t  name  = 'HedgingStrategy',\n",
    "\t\t  bname = '%ss0' % bname,\n",
    "\t\t  prob  = 1,\n",
    "\t\t)\n",
    "\t\tnode.addChild( _create_tree(stochasticset[:], spoints, **kwargs) )\n",
    "\telif stochasticset:\n",
    "\t\tdecisions = enumerate( decision_list )\n",
    "\t\tbname = '%ss%%d' % bname  # the format for the basename of the file\n",
    "\t\tfor enum, d in decisions:\n",
    "\t\t\tkwargs.update(\n",
    "\t\t\t  name  = d,\n",
    "\t\t\t  bname = bname % enum,\n",
    "\t\t\t  prob  = cprob[ d ],\n",
    "\t\t\t)\n",
    "\t\t\tnode.addChild( _create_tree(stochasticset[:], spoints, **kwargs) )\n",
    "\n",
    "\treturn node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree ( stochasticset, spoints, opts ):\n",
    "\ttypes = opts.types\n",
    "\trates = opts.rates\n",
    "\tcprob = opts.conditional_probability\n",
    "\n",
    "\tstochasticset.reverse()\n",
    "\tspoints.sort()\n",
    "\tspoints.reverse()\n",
    "\n",
    "\tkwargs = dict(\n",
    "\t  name      = 'Root',\n",
    "\t  bname     = 'R',\n",
    "\t  types     = types,\n",
    "\t  rates     = rates,\n",
    "\t  cprob     = cprob,\n",
    "\t  decisions = types,\n",
    "\t  stochastic_indices = opts.stochastic_indices,\n",
    "\t  prob      = 1,  # conditional probability, but root guaranteed to occur\n",
    "\t)\n",
    "\treturn _create_tree( stochasticset, spoints, **kwargs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2023, 2025, 2030, 2035, 2040, 2045, 2050]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_spoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31984\\2606583310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSolverFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"solvername\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     ef = sputils.create_EF(\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[0mall_scenario_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mscenario_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Remote\\anaconda3\\envs\\Temoa\\lib\\site-packages\\mpisppy\\utils\\sputils.py\u001b[0m in \u001b[0;36mcreate_EF\u001b[1;34m(scenario_names, scenario_creator, scenario_creator_kwargs, EF_name, suppress_warnings, nonant_for_fixed_vars)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscenario_creator_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mscenario_creator_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     scen_dict = {\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscenario_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mscenario_creator_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscenario_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Remote\\anaconda3\\envs\\Temoa\\lib\\site-packages\\mpisppy\\utils\\sputils.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mscenario_creator_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     scen_dict = {\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscenario_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mscenario_creator_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscenario_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     }\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31984\\2606583310.py\u001b[0m in \u001b[0;36mscenario_creator\u001b[1;34m(scenario_name, branching_factors, data_path)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mhydro_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhydro_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PySP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scenariodata'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbranching_factors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# updated april 2020\n",
    "# DLW: mpisppy version, May 2019\n",
    "#\n",
    "#  ___________________________________________________________________________\n",
    "#\n",
    "#  Pyomo: Python Optimization Modeling Objects\n",
    "#  Copyright 2017 National Technology and Engineering Solutions of Sandia, LLC\n",
    "#  Under the terms of Contract DE-NA0003525 with National Technology and \n",
    "#  Engineering Solutions of Sandia, LLC, the U.S. Government retains certain \n",
    "#  rights in this software.\n",
    "#  This software is distributed under the 3-clause BSD License.\n",
    "#  ___________________________________________________________________________\n",
    "\n",
    "# started as elec3 from Pierre on 8 Dec 2010; removed scenarios\n",
    "#\n",
    "# Imports\n",
    "#\n",
    "import os\n",
    "from pyomo.core import *  # the old fashioned way!\n",
    "import mpisppy.phbase\n",
    "import mpisppy.opt.ph\n",
    "import mpisppy.opt.aph\n",
    "import mpisppy.scenario_tree as scenario_tree\n",
    "import pyomo.environ as pyo\n",
    "from mpisppy.extensions.xhatspecific import XhatSpecific\n",
    "import mpisppy.utils.sputils as sputils\n",
    "\n",
    "##\n",
    "## Setting up a Model\n",
    "##\n",
    "#\n",
    "# Create the model\n",
    "#\n",
    "model = AbstractModel(name=\"elec3\")\n",
    "\n",
    "#\n",
    "# Create sets used to define parameters\n",
    "#\n",
    "\n",
    "### etaps\n",
    "\n",
    "model.nb_etap=Param(within=PositiveIntegers)\n",
    "\n",
    "model.etap = RangeSet(1,model.nb_etap)\n",
    "\n",
    "##\n",
    "## Declaring Params\n",
    "##\n",
    "#\n",
    "model.A=Param(model.etap)\n",
    "model.D=Param(model.etap)\n",
    "\n",
    "model.betaGt=Param()\n",
    "model.betaGh=Param()\n",
    "model.betaDns=Param()\n",
    "\n",
    "model.PgtMax=Param()\n",
    "model.PgtMin=Param()\n",
    "model.PghMin=Param()\n",
    "model.PghMax=Param()\n",
    "\n",
    "model.VMin=Param()\n",
    "model.VMax=Param()\n",
    "\n",
    "model.u=Param(model.etap)\n",
    "model.duracion=Param(model.etap)\n",
    "model.V0=Param()\n",
    "model.T=Param()\n",
    "\n",
    "\n",
    "#bounds and variables\n",
    "\n",
    "def Pgt_bounds(model, t):\n",
    "    return(model.PgtMin,model.PgtMax)\n",
    "model.Pgt = Var(model.etap, bounds=Pgt_bounds, within=NonNegativeReals)\n",
    "\n",
    "def Pgh_bounds(model, t):\n",
    "    return(model.PghMin,model.PghMax)\n",
    "model.Pgh = Var(model.etap, bounds=Pgh_bounds, within=NonNegativeReals)\n",
    "\n",
    "def PDns_bounds(model, t):\n",
    "    return(0,model.D[t])\n",
    "model.PDns = Var(model.etap, bounds=PDns_bounds, within=NonNegativeReals)\n",
    "\n",
    "def Vol_bounds(model, t):\n",
    "    return(model.VMin,model.VMax)\n",
    "model.Vol = Var(model.etap, bounds=Vol_bounds, within=NonNegativeReals)\n",
    "\n",
    "model.sl = Var(within=NonNegativeReals)\n",
    "\n",
    "model.StageCost = Var(model.etap, within=Reals)\n",
    "\n",
    "def discount_rule(model, t):\n",
    "    # Be careful about integer division in python 2\n",
    "    return (1/1.1)**(value(model.duracion[t])/float(value(model.T)))\n",
    "model.r = Param(model.etap,initialize=discount_rule)\n",
    "\n",
    "\n",
    "# objective\n",
    "\n",
    "def StageCostRule(model, t):\n",
    "    if t < value(model.nb_etap):\n",
    "        return model.StageCost[t] == model.r[t] * (model.betaGt * model.Pgt[t] + \\\n",
    "                                     model.betaGh * model.Pgh[t] + \\\n",
    "                                     model.betaDns * model.PDns[t] )\n",
    "    else:\n",
    "        return model.StageCost[t] == (model.r[t] * (model.betaGt * model.Pgt[t] + \\\n",
    "                                     model.betaGh * model.Pgh[t] + \\\n",
    "                                     model.betaDns * model.PDns[t]) + model.sl)\n",
    "\n",
    "model.StageCostConstraint = Constraint(model.etap, rule=StageCostRule)\n",
    "\n",
    "# constraints\n",
    "\n",
    "def fixpgh_rule(model):\n",
    "    return model.Pgh[1] == 60\n",
    "#model.testfixing = Constraint(rule=fixpgh_rule)\n",
    "\n",
    "def demand_rule(model, t):\n",
    "    return model.Pgt[t]+model.Pgh[t]+model.PDns[t]-model.D[t] == 0.0\n",
    "model.demand= Constraint(model.etap, rule=demand_rule)\n",
    "\n",
    "def conserv_rule(model, t):\n",
    "    if t == 1:\n",
    "        return model.Vol[t]-model.V0 <= model.u[t] *(model.A[t]-model.Pgh[t])\n",
    "    else:\n",
    "        return model.Vol[t]-model.Vol[t-1] <= model.u[t] *(model.A[t]-model.Pgh[t])\n",
    "model.conserv= Constraint(model.etap, rule=conserv_rule)\n",
    "\n",
    "def fcfe_rule(model):\n",
    "    return model.sl>= 4166.67*(model.V0-model.Vol[3])\n",
    "model.fcfe= Constraint(rule=fcfe_rule)\n",
    "\n",
    "\n",
    "#\n",
    "# PySP Auto-generated Objective\n",
    "#\n",
    "# minimize: sum of StageCosts\n",
    "#\n",
    "# A active scenario objective equivalent to that generated by PySP is\n",
    "# included here for informational purposes.\n",
    "def total_cost_rule(model):\n",
    "    return sum_product(model.StageCost)\n",
    "model.Objective_rule = Objective(rule=total_cost_rule, sense=minimize)\n",
    "\n",
    "#=============================================================================\n",
    "def MakeAllScenarioTreeNodes(model, bf):\n",
    "    \"\"\" Make the tree nodes and put them in a dictionary.\n",
    "        Assume three stages and a branching factor of bf.\n",
    "        Note: this might not ever be called. (Except maybe for the EF)\n",
    "        Note: mpisppy does not have leaf nodes.\n",
    "        Aside: every rank makes their own nodes; these nodes do not \n",
    "        hold any data computed by a solution algorithm.\n",
    "    \"\"\"\n",
    "    TreeNodes = dict()\n",
    "    TreeNodes[\"ROOT\"] = scenario_tree.ScenarioNode(\"ROOT\",\n",
    "                                                  1.0,\n",
    "                                                  1,\n",
    "                                                  model.StageCost[1],\n",
    "                                                  [model.Pgt[1],\n",
    "                                                   model.Pgh[1],\n",
    "                                                   model.PDns[1],\n",
    "                                                   model.Vol[1]],\n",
    "                                                  model)\n",
    "    for b in range(bf):\n",
    "        ndn = \"ROOT_\"+str(b)\n",
    "        TreeNodes[ndn] = scenario_tree.ScenarioNode(ndn,\n",
    "                                                   1.0/bf,\n",
    "                                                   2,\n",
    "                                                   model.StageCost[2],\n",
    "                                                  [model.Pgt[2],\n",
    "                                                   model.Pgh[2],\n",
    "                                                   model.PDns[2],\n",
    "                                                   model.Vol[2]],\n",
    "                                                    model,\n",
    "                                                    parent_name=\"ROOT\")\n",
    "\n",
    "#=============================================================================\n",
    "def MakeNodesforScen(model, BFs, scennum):\n",
    "    \"\"\" Make just those scenario tree nodes needed by a scenario.\n",
    "        Return them as a list.\n",
    "        NOTE: the nodes depend on the scenario model and are, in some sense,\n",
    "              local to it.\n",
    "        Args:\n",
    "            BFs (list of int): branching factors\n",
    "    \"\"\"\n",
    "    ndn = \"ROOT_\"+str((scennum-1) // BFs[0]) # scennum is one-based\n",
    "    retval = [scenario_tree.ScenarioNode(\"ROOT\",\n",
    "                                         1.0,\n",
    "                                         1,\n",
    "                                         model.StageCost[1],\n",
    "                                         [model.Pgt[1],\n",
    "                                          model.Pgh[1],\n",
    "                                          model.PDns[1],\n",
    "                                          model.Vol[1]],\n",
    "                                         model),\n",
    "              scenario_tree.ScenarioNode(ndn,\n",
    "                                         1.0/BFs[0],\n",
    "                                         2,\n",
    "                                         model.StageCost[2],\n",
    "                                         [model.Pgt[2],\n",
    "                                          model.Pgh[2],\n",
    "                                          model.PDns[2],\n",
    "                                          model.Vol[2]],\n",
    "                                         model, parent_name=\"ROOT\")\n",
    "              ]\n",
    "    return retval\n",
    "\n",
    "#=============================================================================\n",
    "def scenario_creator(scenario_name, branching_factors=None, data_path=None):\n",
    "    \"\"\" The callback needs to create an instance and then attach\n",
    "    the PySP nodes to it in a list _mpisppy_node_list ordered by stages. \n",
    "    Optionally attach _PHrho.\n",
    "    Args:\n",
    "        scenario_name (str): root name of the scenario data file\n",
    "        branching_factors (list of ints): the branching factors\n",
    "        data_path (str, optional): Path to the Hydro data.\n",
    "    \"\"\"\n",
    "    if data_path is None:\n",
    "        hydro_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        data_path = os.sep.join([hydro_dir, 'PySP', 'scenariodata'])\n",
    "    if branching_factors is None:\n",
    "        raise ValueError(\"Hydro scenario_creator requires branching_factors\")\n",
    "\n",
    "    snum = sputils.extract_num(scenario_name)\n",
    "\n",
    "    fname = data_path + os.sep + scenario_name + '.dat'\n",
    "    instance = model.create_instance(fname, name=scenario_name)\n",
    "\n",
    "    instance._mpisppy_node_list = MakeNodesforScen(instance, branching_factors, snum)\n",
    "    return instance\n",
    "\n",
    "#=============================================================================\n",
    "def scenario_denouement(rank, scenario_name, scenario):\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    options = {}\n",
    "    options[\"asynchronousPH\"] = False\n",
    "    options[\"solvername\"] = \"cplex\"\n",
    "    options[\"PHIterLimit\"] = 200\n",
    "    options[\"defaultPHrho\"] = 1\n",
    "    options[\"convthresh\"] = 0.0001\n",
    "    options[\"subsolvedirectives\"] = None\n",
    "    options[\"verbose\"] = False\n",
    "    options[\"display_timing\"] = True\n",
    "    options[\"display_progress\"] = True\n",
    "    options[\"iter0_solver_options\"] = None\n",
    "    options[\"iterk_solver_options\"] = None\n",
    "    options[\"branching_factors\"] = [3, 3]\n",
    "    options[\"xhat_looper_options\"] =  {\"xhat_solver_options\":\\\n",
    "                                         None,\n",
    "                                         \"scen_limit\": 3,\n",
    "                                         \"dump_prefix\": \"delme\",\n",
    "                                         \"csvname\": \"looper.csv\"}\n",
    "\n",
    "    # branching factor (3 stages is hard-wired)\n",
    "    BFs = options[\"branching_factors\"]\n",
    "    ScenCount = BFs[0] * BFs[1]\n",
    "    all_scenario_names = list()\n",
    "    for sn in range(ScenCount):\n",
    "        all_scenario_names.append(\"Scen\"+str(sn+1))\n",
    "    # end hardwire\n",
    "\n",
    "    # This is multi-stage, so we need to supply node names\n",
    "    all_nodenames = sputils.create_nodenames_from_branching_factors(BFs)\n",
    "\n",
    "    # **** ef ****\n",
    "    solver = pyo.SolverFactory(options[\"solvername\"])\n",
    "\n",
    "    ef = sputils.create_EF(\n",
    "        all_scenario_names,\n",
    "        scenario_creator,\n",
    "        scenario_creator_kwargs={\"branching_factors\": BFs},\n",
    "    )\n",
    "    results = solver.solve(ef, tee=options[\"verbose\"])\n",
    "    print('EF objective value:', pyo.value(ef.EF_Obj))\n",
    "    sputils.ef_nonants_csv(ef, \"vardump.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temoa_OEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
