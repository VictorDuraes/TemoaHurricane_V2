{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from haversine import haversine_vector, Unit\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "State=\"NC\"\n",
    "GeneratorDataPath=\"./EIAData/february_generator2023.xlsx\"\n",
    "HazusDataPath=\"./HazusData/Hazus_NC_Hurricane.shp\"\n",
    "\n",
    "\n",
    "Vintages=np.arange(2022,1900,-2) #[2022 to 2020), [2020 to 2018) Needs to start from earlier date to later date. Needs equal spacing\n",
    "\n",
    "AggregationDistance=16#[km], Distance technologies need to be in order to get aggregated with each other \n",
    "#Only technologies of the same vintage period, and type will be aggregated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Convert Excel Table to Sql data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generation data from: Preliminary Monthly Electric Generator Inventory (based on Form EIA-860M as a supplement to Form EIA-860)\n",
    "\n",
    "#Read File\n",
    "df = pd.read_excel(GeneratorDataPath, sheet_name ='Operating',skiprows=2)\n",
    "InState=df[\"Plant State\"]==State #Filter for NC\n",
    "df=df[InState]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Battery Data, some elements do not have NameplateEnergyCapacity(MWh) and were removed:\n",
      " Plant ID:\n",
      "MWH_BA_64640\n"
     ]
    }
   ],
   "source": [
    "#   Some plants may have multiple generators commissioned at different times\n",
    "#   we are aggregating the capacity of these generators per year\n",
    "\n",
    "#   We can have multiple vintages (years) of the same plant. As generators may be comissioned at different times\n",
    "df_AggregateGen = pd.DataFrame(columns=[\"PlantID\", \"SourceCode\", \"MoverCode\", \"OperatingYear\",\"NameplateCapacity(MW)\",\"NetSummerCapacity(MW)\",\"NetWinterCapacity(MW)\",\n",
    " \"NameplateEnergyCapacity(MWh)\", \"Latitude\",\"Longitude\",\"Technology\"])\n",
    "\n",
    "for ID in df[\"Plant ID\"].unique().astype(int):\n",
    "    #Same Plant data\n",
    "    SameIds   = df[\"Plant ID\"]==ID\n",
    "    df_tmp1    = df[SameIds]\n",
    "\n",
    "    SourceCode=df_tmp1[\"Energy Source Code\"]\n",
    "    #Same Energy Source Code data\n",
    "    for UniqueSC in SourceCode.unique():\n",
    "        SameIds    = df_tmp1[\"Energy Source Code\"]==UniqueSC\n",
    "        df_tmp2    = df_tmp1[SameIds]\n",
    "\n",
    "        MoverCode=df_tmp2[\"Prime Mover Code\"]\n",
    "        #Same Mover Code data\n",
    "        for UniqueMC in MoverCode.unique():\n",
    "            SameIds    = df_tmp2[\"Prime Mover Code\"]==UniqueMC\n",
    "            df_tmp3    = df_tmp2[SameIds]\n",
    "\n",
    "            OperatingYear=df_tmp3[\"Operating Year\"]\n",
    "            OperatingYear=OperatingYear.sort_values(ascending=False)\n",
    "            #Same Year Code data\n",
    "            for UniqueY in OperatingYear.unique():\n",
    "                SameIds    = df_tmp3[\"Operating Year\"]==UniqueY\n",
    "                df_tmp4    = df_tmp3[SameIds]\n",
    "\n",
    "                NameplateEnergyCapacity=np.sum(df_tmp4[\"Nameplate Energy Capacity (MWh)\"])\n",
    "                NameplateCapacity=np.sum(df_tmp4[\"Nameplate Capacity (MW)\"])\n",
    "                NetSummerCapacity=np.sum(df_tmp4[\"Net Summer Capacity (MW)\"])\n",
    "                NetWinterCapacity=np.sum(df_tmp4[\"Net Winter Capacity (MW)\"])\n",
    "\n",
    "                Latitude  = df_tmp4[\"Latitude\"].iloc[0]\n",
    "                Longitude = df_tmp4[\"Longitude\"].iloc[0]\n",
    "                Technology= df_tmp4[\"Technology\"].iloc[0]\n",
    "\n",
    "                NewPlantID = UniqueSC + \"_\" + UniqueMC + \"_\" + str(ID) \n",
    "\n",
    "                Data=[[NewPlantID, UniqueSC, UniqueMC, UniqueY, NameplateCapacity, NetSummerCapacity, NetWinterCapacity,NameplateEnergyCapacity,\n",
    "                Latitude,Longitude,Technology]]\n",
    "\n",
    "                df_AggregateGen=pd.concat([df_AggregateGen,pd.DataFrame(Data,columns=df_AggregateGen.columns)],ignore_index=True)\n",
    "\n",
    "#Delete technologies that are after the maximum vintage period\n",
    "df_AggregateGen=df_AggregateGen[df_AggregateGen[\"OperatingYear\"]<=np.max(Vintages)]\n",
    "\n",
    "#Check for missing data\n",
    "if sum(df_AggregateGen[df_AggregateGen[\"MoverCode\"]==\"BA\"][\"NameplateEnergyCapacity(MWh)\"]==' '):\n",
    "    EliminateIdx=(df_AggregateGen[\"MoverCode\"]==\"BA\") * (df_AggregateGen[\"NameplateEnergyCapacity(MWh)\"]==' ')\n",
    "    EliminateId=df_AggregateGen[EliminateIdx][\"PlantID\"]\n",
    "    print(\"Check Battery Data, some elements do not have NameplateEnergyCapacity(MWh) and were removed:\\n Plant ID:\")\n",
    "    [print(EliminateId.iloc[i]) for i in range(EliminateId.shape[0])]\n",
    "\n",
    "    df_AggregateGen=df_AggregateGen[~EliminateIdx]\n",
    "\n",
    "df_AggregateGen = df_AggregateGen.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate per radius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grup generators too close to each other, in the same vintage bracket\n",
    "#and of the same type and fuel \"SourceCode\", \"MoverCode\"\n",
    "\n",
    "#   We can have multiple vintages (years) of the same plant. As generators may be comissioned at different times\n",
    "df_AggregateGen2 = pd.DataFrame(columns=[\"PlantID\", \"SourceCode\", \"MoverCode\", \"Vintage\",\"OperatingYear\",\"NameplateCapacity(MW)\",\"NetSummerCapacity(MW)\",\"NetWinterCapacity(MW)\",\n",
    " \"NameplateEnergyCapacity(MWh)\", \"Latitude\",\"Longitude\",\"Technology\"])\n",
    "\n",
    "#Compute distance matrix for each element on df_Aggregation\n",
    "Latitude=np.reshape(df_AggregateGen[\"Latitude\"].to_numpy(),(df_AggregateGen[\"Latitude\"].shape[0],1))\n",
    "Latitude=np.tile(Latitude,(1,Latitude.shape[0]))\n",
    "\n",
    "Longitude=np.reshape(df_AggregateGen[\"Longitude\"].to_numpy(),(df_AggregateGen[\"Longitude\"].shape[0],1))\n",
    "Longitude=np.tile(Longitude,(1,Longitude.shape[0]))\n",
    "\n",
    "X_LatLong=np.array([np.reshape(Latitude,(-1)),np.reshape(Longitude,(-1))]).T\n",
    "Y_LatLong=np.array([np.reshape(Latitude.T,(-1)),np.reshape(Longitude.T,(-1))]).T\n",
    "\n",
    "Distances=haversine_vector(X_LatLong,Y_LatLong, Unit.KILOMETERS)\n",
    "Distances=np.reshape(Distances,(Latitude.shape[0],Longitude.shape[0])) #Distances between any pair of available generators\n",
    "\n",
    "ID=0\n",
    "while df_AggregateGen.shape[0]!=0:\n",
    "    ID=ID+1\n",
    "    RefGenerator=df_AggregateGen.iloc[0]\n",
    "    IdxInDistance=Distances[0,:]<=AggregationDistance\n",
    "    IdxSameSource=df_AggregateGen[\"SourceCode\"]==RefGenerator[\"SourceCode\"]\n",
    "    IdxSameMover=df_AggregateGen[\"MoverCode\"]==RefGenerator[\"MoverCode\"]\n",
    "\n",
    "    #Vintage Bracket of the current generator\n",
    "    if np.min(np.abs(Vintages-RefGenerator[\"OperatingYear\"]))==0:\n",
    "        VintageMax=RefGenerator[\"OperatingYear\"]\n",
    "        VintageMin=RefGenerator[\"OperatingYear\"]-(Vintages[0]-Vintages[1])\n",
    "\n",
    "    else:\n",
    "        IdxVintage=np.argsort(np.abs(Vintages-RefGenerator[\"OperatingYear\"]))[0:2] \n",
    "        VintageMax=np.max(Vintages[IdxVintage])\n",
    "        VintageMin=np.min(Vintages[IdxVintage])\n",
    "\n",
    "    IdxSameVintage=(df_AggregateGen[\"OperatingYear\"]>VintageMin)*(df_AggregateGen[\"OperatingYear\"]<=VintageMax)\n",
    "\n",
    "    IdxToAggregate=IdxSameVintage*IdxSameMover*IdxSameSource*IdxInDistance\n",
    "\n",
    "    df_tmp=df_AggregateGen[IdxToAggregate]\n",
    "\n",
    "    NameplateCapacity=np.sum(df_tmp[\"NameplateCapacity(MW)\"])\n",
    "    NetSummerCapacity=np.sum(df_tmp[\"NetSummerCapacity(MW)\"])\n",
    "    NetWinterCapacity=np.sum(df_tmp[\"NetWinterCapacity(MW)\"])\n",
    "    NameplateEnergyCapacity=np.sum(df_tmp[\"NameplateEnergyCapacity(MWh)\"])\n",
    "\n",
    "    #Lat Long, vintage and year of operation are estimated based on a weighted average of the Nplate Capacity\n",
    "    NPC=df_tmp[\"NameplateCapacity(MW)\"]\n",
    "    Latitude=np.sum(NPC*df_tmp[\"Latitude\"])/NameplateCapacity\n",
    "    Longitude=np.sum(NPC*df_tmp[\"Longitude\"])/NameplateCapacity\n",
    "    OperatingYear=np.sum(NPC*df_tmp[\"OperatingYear\"])/NameplateCapacity\n",
    "    VintageYear=Vintages[np.argmin(np.abs(Vintages-OperatingYear))]\n",
    "\n",
    "    NewPlantID = UniqueSC + \"_\" + UniqueMC + \"_\" + str(ID) \n",
    "    Technology= RefGenerator[\"Technology\"]\n",
    "\n",
    "    Data=[[NewPlantID, RefGenerator[\"SourceCode\"], RefGenerator[\"MoverCode\"], VintageYear, OperatingYear,\n",
    "    NameplateCapacity, NetSummerCapacity, NetWinterCapacity, NameplateEnergyCapacity,\n",
    "    Latitude, Longitude, Technology]]\n",
    "\n",
    "    df_AggregateGen2=pd.concat([df_AggregateGen2,pd.DataFrame(Data,columns=df_AggregateGen2.columns)],ignore_index=True)\n",
    "\n",
    "    #delete generators that were aggregated\n",
    "    df_AggregateGen=df_AggregateGen[~IdxToAggregate]\n",
    "    Distances=Distances[~IdxToAggregate,:]\n",
    "    Distances=Distances[:,~IdxToAggregate]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All generators were properly mapped\n"
     ]
    }
   ],
   "source": [
    "#Do not run Aggregate per radius if you want to aggregate using .shp files\n",
    "shapefile = gpd.read_file(HazusDataPath)\n",
    "Hazus1000=shapefile.f1000yr\n",
    "\n",
    "Region1Idx=Hazus1000>=130 # Cat 4 hurricane and above 130mph\n",
    "Region2Idx=(Hazus1000>=111)*(Hazus1000<130) # Cat 3 hurricane 111-129mph\n",
    "Region3Idx=Hazus1000<111 # Cat 1-2 hurricane and bellow 110mph\n",
    "\n",
    "Region1Data=shapefile[Region1Idx] \n",
    "Region2Data=shapefile[Region2Idx]    \n",
    "Region3Data=shapefile[Region3Idx]     \n",
    "\n",
    "new_polyR1 = unary_union([Region1Data.iloc[j][\"geometry\"] for j in range(Region1Data.shape[0])])\n",
    "new_polyR2 = unary_union([Region2Data.iloc[j][\"geometry\"] for j in range(Region2Data.shape[0])])\n",
    "new_polyR3 = unary_union([Region3Data.iloc[j][\"geometry\"] for j in range(Region3Data.shape[0])])\n",
    "\n",
    "df_AggregateGen[\"Region\"]=''\n",
    "#Assign region for each generation \n",
    "\n",
    "for i in range(df_AggregateGen.shape[0]):\n",
    "    Latitude=df_AggregateGen.iloc[i][\"Latitude\"]\n",
    "    Longitude=df_AggregateGen.iloc[i][\"Longitude\"]\n",
    "\n",
    "    if new_polyR1.contains(Point(Longitude,Latitude)):\n",
    "        df_AggregateGen.at[i,\"Region\"]='R1'\n",
    "\n",
    "    elif new_polyR2.contains(Point(Longitude,Latitude)):\n",
    "        df_AggregateGen.at[i,\"Region\"]='R2'\n",
    "    \n",
    "    elif new_polyR3.contains(Point(Longitude,Latitude)):\n",
    "        df_AggregateGen.at[i,\"Region\"]='R3'\n",
    "\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        break\n",
    "\n",
    "if sum(df_AggregateGen.Region=='')==0:\n",
    "    print(\"All generators were properly mapped\")\n",
    "else:\n",
    "    print(\"Some generators were no properly mapped to the Hazus data\\\n",
    "    check Hazus and the location of generators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AggregateGen3 = pd.DataFrame(columns=[\"PlantID\", \"SourceCode\", \"MoverCode\", \"Vintage\",\"NameplateCapacity(MW)\",\"NetSummerCapacity(MW)\",\"NetWinterCapacity(MW)\",\n",
    " \"NameplateEnergyCapacity(MWh)\",\"Technology\",\"Region\"])\n",
    "\n",
    "\n",
    "for Region in [\"R1\",\"R2\",\"R3\"]:\n",
    "\n",
    "    df_tmp1=df_AggregateGen[df_AggregateGen[\"Region\"]==Region]\n",
    "\n",
    "    SourceCode=df_tmp1[\"SourceCode\"]\n",
    "    #Same Energy Source Code data\n",
    "    for UniqueSC in SourceCode.unique():\n",
    "        SameIds    = df_tmp1[\"SourceCode\"]==UniqueSC\n",
    "        df_tmp2    = df_tmp1[SameIds]\n",
    "\n",
    "        MoverCode=df_tmp2[\"MoverCode\"]\n",
    "        #Same Mover Code data\n",
    "        for UniqueMC in MoverCode.unique():\n",
    "            SameIds    = df_tmp2[\"MoverCode\"]==UniqueMC\n",
    "            df_tmp3    = df_tmp2[SameIds]\n",
    "            \n",
    "            OperatingYear=df_tmp3[\"OperatingYear\"]\n",
    "            for i in range(len(Vintages[0:-1])):\n",
    "\n",
    "                IdxsIn=(OperatingYear<=Vintages[i]+(Vintages[0]-Vintages[1])/2) * (OperatingYear>Vintages[i]-(Vintages[0]-Vintages[1])/2)\n",
    "                if sum(IdxsIn)!=0:\n",
    "                    df_tmp4    = df_tmp3[IdxsIn]\n",
    "\n",
    "                    NameplateCapacity=np.sum(df_tmp4[\"NameplateCapacity(MW)\"])\n",
    "                    NetSummerCapacity=np.sum(df_tmp4[\"NetSummerCapacity(MW)\"])\n",
    "                    NetWinterCapacity=np.sum(df_tmp4[\"NetWinterCapacity(MW)\"])\n",
    "                    NameplateEnergyCapacity=np.sum(df_tmp4[\"NameplateEnergyCapacity(MWh)\"])\n",
    "                    \n",
    "                    NewPlantID = Region + \"_\" + UniqueSC + \"_\" + UniqueMC\n",
    "                    Technology= df_tmp4[\"Technology\"].iloc[0]\n",
    "\n",
    "                    Data=[[NewPlantID, UniqueSC, UniqueMC, Vintages[i] ,\n",
    "                    NameplateCapacity, NetSummerCapacity, NetWinterCapacity, NameplateEnergyCapacity,\n",
    "                    Technology,Region]]\n",
    "\n",
    "                    df_AggregateGen3=pd.concat([df_AggregateGen3,pd.DataFrame(Data,columns=df_AggregateGen3.columns)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AggregateGen3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AggregateGen3.to_excel(\"test.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Temoa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
